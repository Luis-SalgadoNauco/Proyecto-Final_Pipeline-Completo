# Proyecto Final â€“ Pipeline de Datos (Semana 3)

## DescripciÃ³n
Este proyecto corresponde al **Mes 3 del curso de AnÃ¡lisis de Datos**, enfocado en **Herramientas ETL y un Proyecto Final**.  
Durante esta semana se diseÃ±a, implementa y documenta un **pipeline de datos completo**, siguiendo buenas prÃ¡cticas de arquitectura, manejo de errores y preparaciÃ³n para producciÃ³n.

El repositorio funciona como una **bitÃ¡cora tÃ©cnica**, donde el README se actualiza diariamente con el avance del proyecto.

---

## Objetivo General de la Semana
- DiseÃ±ar una arquitectura de datos alineada a requisitos de negocio
- Implementar un pipeline de datos end-to-end
- Aplicar manejo de errores y logging
- Validar y probar el pipeline
- Optimizar rendimiento y documentar el sistema

---

## ğŸ› ï¸ TecnologÃ­as utilizadas
- Python
- Pandas
- PostgreSQL
- Apache Airflow
- Linux (Ubuntu)
- Git / GitHub
- Markdown para documentaciÃ³n

---

## Desarrollo de la semana

### DÃ­a 1 â€“ DiseÃ±o de Arquitectura Completa

#### Objetivo del dÃ­a
DiseÃ±ar una arquitectura bÃ¡sica de datos para un sistema de analÃ­tica,
definiendo componentes, decisiones tecnolÃ³gicas y criterios de diseÃ±o.

---

#### Actividades realizadas
- IdentificaciÃ³n de componentes principales del sistema
- DefiniciÃ³n del flujo de datos (ingesta â†’ procesamiento â†’ almacenamiento â†’ consumo)
- DocumentaciÃ³n de decisiones arquitectÃ³nicas

---

#### Arquitectura definida
Se definiÃ³ una arquitectura simplificada orientada a analÃ­tica de retail, considerando fuentes de datos, procesamiento, almacenamiento y consumo.

---

#### Decisiones arquitectÃ³nicas
- Base de datos: PostgreSQL por su madurez y facilidad de uso
- OrquestaciÃ³n: Apache Airflow como estÃ¡ndar de la industria
- VisualizaciÃ³n: Herramientas orientadas a negocio

---

#### VerificaciÃ³n â€“ DÃ­a 1

**Â¿QuÃ© factores considerarÃ­as al elegir entre una arquitectura simple vs compleja?**
- Volumen y frecuencia de datos
- Requisitos del negocio
- Presupuesto disponible
- Capacidad y experiencia del equipo
- Escalabilidad futura

**Â¿CÃ³mo comunicar decisiones arquitectÃ³nicas?**
- A equipos tÃ©cnicos: diagramas, flujos y justificaciÃ³n tÃ©cnica
- A stakeholders de negocio: impacto, beneficios y riesgos

---

### DÃ­a 2 â€“ ImplementaciÃ³n del Pipeline End-to-End

#### Objetivo del dÃ­a
Implementar un pipeline bÃ¡sico de datos en Python que represente un flujo de extremo a extremo, incorporando manejo explÃ­cito de errores y logging, dejando la base preparada para una futura orquestaciÃ³n con Airflow.

---

#### Actividades realizadas
- Uso de un entorno virtual (`venv`) para aislar dependencias
- DefiniciÃ³n de un pipeline secuencial con pasos claros
- ImplementaciÃ³n de manejo de errores mediante excepciones controladas
- IncorporaciÃ³n de logging para trazabilidad de ejecuciÃ³n
- EjecuciÃ³n del pipeline y validaciÃ³n de comportamiento ante errores

El cÃ³digo de implementaciÃ³n se encuentra en:
- `src/pipeline.py`
- `src/utils.py`

---

#### DescripciÃ³n del pipeline
El pipeline implementado consta de tres etapas principales:
1. Captura de datos desde una fuente simulada
2. ValidaciÃ³n y limpieza de datos
3. Persistencia de datos procesados

Se simula un error en la etapa de validaciÃ³n para comprobar el correcto manejo de fallos.

---

#### Manejo de errores y logging
El pipeline:
- Detecta errores de forma explÃ­cita
- Registra eventos y excepciones en logs
- Detiene la ejecuciÃ³n de manera controlada ante errores crÃ­ticos

Esto evita resultados incorrectos y facilita el diagnÃ³stico.

---

#### VerificaciÃ³n â€“ DÃ­a 2

**Â¿QuÃ© diferencia hay entre un pipeline que falla silenciosamente y uno con buen manejo de errores?**
Un pipeline con manejo de errores:
- Detecta y registra fallos
- Facilita el mantenimiento
- Protege la calidad de los datos

Un pipeline que falla silenciosamente:
- Oculta errores
- Genera resultados incorrectos
- Dificulta la detecciÃ³n de problemas en producciÃ³n

**Â¿CÃ³mo decidir cuÃ¡ndo reintentar vs abortar una ejecuciÃ³n?**
- Reintentar ante errores transitorios (red, APIs externas)
- Abortar ante errores de validaciÃ³n o lÃ³gica de negocio

---
 
# DÃ­a 3 â€“ ValidaciÃ³n y Pruebas

## Objetivo del DÃ­a
Implementar pruebas bÃ¡sicas para validar la lÃ³gica del pipeline de datos, asegurando que los cÃ¡lculos crÃ­ticos funcionen correctamente antes de avanzar hacia etapas de optimizaciÃ³n o despliegue.

---

## Actividades Realizadas

### IntroducciÃ³n al Testing en Pipelines de Datos
Se revisÃ³ la importancia del testing en pipelines de datos, considerando que estos procesan informaciÃ³n crÃ­tica para el negocio. Las pruebas permiten detectar errores tempranamente y evitar regresiones cuando el cÃ³digo evoluciona.

Se identificaron los principales tipos de pruebas aplicables a pipelines:
- **Pruebas unitarias**
- **Pruebas de integraciÃ³n**
- **ValidaciÃ³n de calidad de datos**

---

### ImplementaciÃ³n de FunciÃ³n a Testear
Se utilizÃ³ una funciÃ³n de negocio encargada de calcular el total de ventas por producto, considerando cantidad y precio. Esta funciÃ³n forma parte del mÃ³dulo `utils` del proyecto y representa una lÃ³gica crÃ­tica del pipeline.

---

### CreaciÃ³n de Prueba Unitaria BÃ¡sica
Se creÃ³ una prueba unitaria en la carpeta `tests/`, validando:
- La correcta acumulaciÃ³n de ventas por producto
- El manejo de mÃºltiples registros para un mismo producto

La prueba fue implementada sin frameworks externos, utilizando `assert`, alineado al enfoque del curso y permitiendo una validaciÃ³n clara y directa de la lÃ³gica.

La ejecuciÃ³n de la prueba fue **exitosa**, confirmando el correcto funcionamiento de la funciÃ³n evaluada.

---

## VerificaciÃ³n â€“ Respuestas

### Â¿Por quÃ© es importante testear pipelines de datos?
Porque los pipelines procesan datos crÃ­ticos para el negocio. Un error no detectado puede propagarse hasta reportes o dashboards, generando decisiones incorrectas. El testing asegura confiabilidad y calidad en el procesamiento.

---

### Â¿QuÃ© tipos de errores son mÃ¡s comunes y cÃ³mo detectarlos?
- **Errores de lÃ³gica**: detectados mediante pruebas unitarias
- **Errores de integraciÃ³n**: detectados al probar componentes en conjunto
- **Errores de calidad de datos**: detectados mediante validaciones de completitud, exactitud y consistencia

---

### DÃ­a 4 â€“ OptimizaciÃ³n y Rendimiento
*(Pendiente)*

#### VerificaciÃ³n â€“ DÃ­a 4
*(Pendiente)*

---

### DÃ­a 5 â€“ DocumentaciÃ³n y PresentaciÃ³n
*(Pendiente)*

#### VerificaciÃ³n â€“ DÃ­a 5
*(Pendiente)*

---

## Estructura del proyecto

```text
week_3_final_project/
â”œâ”€â”€ architecture/
â”‚   â””â”€â”€ architecture_diagram.txt
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ architecture_retail.md
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ pipeline.log
â”œâ”€â”€ notes/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pipeline.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_utils.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
